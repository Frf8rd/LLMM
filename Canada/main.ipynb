{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fd8f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "206e99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d236638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Datasets/dinosaur_dataset.csv'\n",
    "weights_file = 'Model_save/dino_translator_bidirectional_emb.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "242ecf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "latent_dim = 512\n",
    "start_token = '\\t'\n",
    "end_token = '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20f7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Greutățile modelului au fost încărcate.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df.dropna(subset=['english', 'dinosaur'], inplace=True)\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = str(text).strip().lower()\n",
    "    text = re.sub(r'[^a-z0-9\\?\\.\\!,;:\\'\\-\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'([?.!,;:])', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['english'] = df['english'].apply(normalize_text)\n",
    "df['dinosaur'] = df['dinosaur'].apply(normalize_text)\n",
    "\n",
    "input_texts = df['english'].tolist()\n",
    "target_texts = [start_token + t + end_token for t in df['dinosaur'].tolist()]\n",
    "\n",
    "\n",
    "input_chars = sorted(list(set(''.join(input_texts))))\n",
    "target_chars = sorted(list(set(''.join(target_texts))))\n",
    "\n",
    "input_token_index = {c: i+1 for i, c in enumerate(input_chars)}\n",
    "target_token_index = {c: i+1 for i, c in enumerate(target_chars)}\n",
    "if start_token not in target_token_index:\n",
    "    target_token_index[start_token] = max(target_token_index.values()) + 1\n",
    "if end_token not in target_token_index:\n",
    "    target_token_index[end_token] = max(target_token_index.values()) + 1\n",
    "\n",
    "reverse_target_char_index = {i: c for c, i in target_token_index.items()}\n",
    "reverse_input_char_index = {i: c for c, i in input_token_index.items()}\n",
    "\n",
    "num_encoder_tokens = len(input_token_index) + 1\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "max_encoder_seq_length = max(len(t) for t in input_texts)\n",
    "max_decoder_seq_length = max(len(t) for t in target_texts)\n",
    "\n",
    "def texts_to_sequences(texts, token_index):\n",
    "    seqs = [[token_index[c] for c in t if c in token_index] for t in texts]\n",
    "    return seqs\n",
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "\n",
    "encoder_embedding = Embedding(input_dim=num_encoder_tokens, output_dim=embedding_dim, mask_zero=True, name='encoder_embedding')\n",
    "decoder_embedding = Embedding(input_dim=num_decoder_tokens, output_dim=embedding_dim, mask_zero=True, name='decoder_embedding')\n",
    "\n",
    "enc_embedded = encoder_embedding(encoder_inputs)\n",
    "dec_embedded = decoder_embedding(decoder_inputs)\n",
    "\n",
    "encoder_bi = Bidirectional(LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.1), name='encoder_bidirectional')\n",
    "enc_outputs_and_states = encoder_bi(enc_embedded)\n",
    "encoder_outputs = enc_outputs_and_states[0]\n",
    "state_f_h, state_f_c, state_b_h, state_b_c = enc_outputs_and_states[1:5]\n",
    "state_h = Concatenate()([state_f_h, state_b_h])\n",
    "state_c = Concatenate()([state_f_c, state_b_c])\n",
    "state_h = Dense(latent_dim, activation='tanh', name='state_h_projection')(state_h)\n",
    "state_c = Dense(latent_dim, activation='tanh', name='state_c_projection')(state_c)\n",
    "encoder_states_for_decoder = [state_h, state_c]\n",
    "\n",
    "decoder_lstm_1 = LSTM(latent_dim, return_sequences=True, return_state=True,\n",
    "                      dropout=0.2, recurrent_dropout=0.1, name='decoder_lstm_1')\n",
    "decoder_out_1, dec_h1, dec_c1 = decoder_lstm_1(dec_embedded, initial_state=encoder_states_for_decoder)\n",
    "decoder_dropout = Dropout(0.3)(decoder_out_1)\n",
    "\n",
    "decoder_lstm_2 = LSTM(latent_dim, return_sequences=True, return_state=True,\n",
    "                      dropout=0.2, recurrent_dropout=0.1, name='decoder_lstm_2')\n",
    "decoder_out_2, dec_h2, dec_c2 = decoder_lstm_2(decoder_dropout)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_output')\n",
    "decoder_outputs = decoder_dense(decoder_out_2)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.load_weights(weights_file)\n",
    "print(\" Greutățile modelului au fost încărcate.\")\n",
    "\n",
    "\n",
    "encoder_model_inf = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
    "\n",
    "decoder_single_input = Input(shape=(1,), name='decoder_single_input')\n",
    "dec_emb_single = decoder_embedding(decoder_single_input)\n",
    "dec_state_h1 = Input(shape=(latent_dim,), name='dec_state_h1')\n",
    "dec_state_c1 = Input(shape=(latent_dim,), name='dec_state_c1')\n",
    "dec_state_h2 = Input(shape=(latent_dim,), name='dec_state_h2')\n",
    "dec_state_c2 = Input(shape=(latent_dim,), name='dec_state_c2')\n",
    "\n",
    "dec_out_1_step, new_h1, new_c1 = decoder_lstm_1(dec_emb_single, initial_state=[dec_state_h1, dec_state_c1])\n",
    "dec_out_1_step = Dropout(0.3)(dec_out_1_step)\n",
    "dec_out_2_step, new_h2, new_c2 = decoder_lstm_2(dec_out_1_step, initial_state=[dec_state_h2, dec_state_c2])\n",
    "dec_pred_step = decoder_dense(dec_out_2_step)\n",
    "\n",
    "decoder_model_inf = Model(\n",
    "    [decoder_single_input, dec_state_h1, dec_state_c1, dec_state_h2, dec_state_c2],\n",
    "    [dec_pred_step, new_h1, new_c1, new_h2, new_c2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33836b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temperature(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.maximum(preds, 1e-8)  # evităm valori negative\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(preds), p=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8661a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_english_to_dinosaur(english_text, temperature=0.1, max_output_length=None):\n",
    "    if max_output_length is None:\n",
    "        max_output_length = max_decoder_seq_length\n",
    "\n",
    "    normalized = normalize_text(english_text)\n",
    "    seq = [input_token_index[c] for c in normalized if c in input_token_index]\n",
    "    seq = seq[:max_encoder_seq_length]\n",
    "    encoder_seq = pad_sequences([seq], maxlen=max_encoder_seq_length, padding='post')\n",
    "\n",
    "    enc_outs, enc_h_proj, enc_c_proj = encoder_model_inf.predict(encoder_seq, verbose=0)\n",
    "    h1, c1 = enc_h_proj, enc_c_proj\n",
    "    h2, c2 = np.zeros((1, latent_dim)), np.zeros((1, latent_dim))\n",
    "    start_idx = target_token_index[start_token]\n",
    "    target_seq = np.array([[start_idx]], dtype='int32')\n",
    "\n",
    "    decoded_chars = []\n",
    "    for _ in range(max_output_length + 10):\n",
    "        preds, new_h1, new_c1, new_h2, new_c2 = decoder_model_inf.predict(\n",
    "            [target_seq, h1, c1, h2, c2], verbose=0\n",
    "        )\n",
    "        preds = preds[0, 0]\n",
    "        sampled_idx = sample_with_temperature(preds, temperature=temperature)\n",
    "        if sampled_idx == 0:\n",
    "            break\n",
    "        sampled_char = reverse_target_char_index.get(sampled_idx, '')\n",
    "        if sampled_char == end_token or sampled_char == '':\n",
    "            break\n",
    "        decoded_chars.append(sampled_char)\n",
    "        target_seq = np.array([[sampled_idx]], dtype='int32')\n",
    "        h1, c1, h2, c2 = new_h1, new_c1, new_h2, new_c2\n",
    "\n",
    "    return ''.join(decoded_chars).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbac827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTARE TRADUCERI\n",
      "[1] EN: 'Sigmoid organized jurassic AI conferences.' -> DN: 'sriigmrooriid roorgraanriizrooriid riintreellriigreencree .'\n",
      "[2] EN: 'When did Sigmoid teach jurassic AI?' -> DN: 'whreen driid scriireentriistsraaraar traaruught nreeruurraal ?'\n",
      "[3] EN: 'The jurassic era democratized AI education.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[4] EN: 'The jurassic period had high sea levels.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[5] EN: 'Dinosaurs learned about neural networks.' -> DN: 'driinroosraaruursraaraar lreeraarnrooriid raabrooruut nreetwroorksraaraar .'\n",
      "[6] EN: 'Who studied the extinction event?' -> DN: 'whreen driid zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[7] EN: 'Sigmoid taught jurassic computer vision.' -> DN: 'sriigmrooriid traaruught riintreellriigreencree croompruutreer .'\n",
      "[8] EN: 'The triassic period came before the jurassic.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[9] EN: 'The jurassic period featured giant sauropods.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[10] EN: 'The jurassic era had AI competitions.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[11] EN: 'The jurassic period had data science challenges.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[12] EN: 'Sigmoid taught dinosaurs about deep learning.' -> DN: 'sriigmrooriid traaruught jruurraassriic preerriirood craamree breefroorree zraa jruurraassriic .'\n",
      "[13] EN: 'Dinosaurs ruled during the jurassic period.' -> DN: 'driinroosraaruursraaraar struudriirooriid zraa reedruucraasrruun .'\n",
      "[14] EN: 'When did LMML event first launch?' -> DN: 'whreen driid sriigmrooriid lreeraarnrooriid nreetwroorksraaraar ?'\n",
      "[15] EN: 'Sigmoid organized jurassic programming events.' -> DN: 'sriigmrooriid roorgraanriizrooriid riintreellriigreencree .'\n",
      "[16] EN: 'The jurassic period featured AI workshops.' -> DN: 'zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[17] EN: 'When did Sigmoid begin its mission?' -> DN: 'whreen driid driinroosraaruursraaraar sroolvrooriid nreetwroorksraaraar ?'\n",
      "[18] EN: 'Dinosaurs learned about artificial intelligence.' -> DN: 'driinroosraaruursraaraar lreeraarnrooriid raabrooruut nreetwroorksraaraar .'\n",
      "[19] EN: 'Where did the asteroid impact occur?' -> DN: 'whreerree driid zraa reevreent rooccruur ?'\n",
      "[20] EN: 'Who analyzed the fossil evidence?' -> DN: 'whreen driid lmml reevreent friirst lraaruunkr ?'\n",
      "[21] EN: 'Dinosaurs solved jurassic data problems.' -> DN: 'driinroosraaruursraaraar sroolvrooriid riintreellriigreencree .'\n",
      "[22] EN: 'Scientists study the jurassic period fossils.' -> DN: 'scriireentriistsraaraar struudriirooriid zraa croompreetriitriiroonsraaraar .'\n",
      "[23] EN: 'When did Sigmoid host its first event?' -> DN: 'whreen driid scriireentriistsraaraar traaruught nreetwroorksraaraar ?'\n",
      "[24] EN: 'The jurassic period influenced Earth's climate.' -> DN: 'zraa jruurraassriic preerriirood riinflruureencrooriid reeraarkl ' s clriimraatree .'\n",
      "[25] EN: 'Sigmoid discovered dinosaur algorithms.' -> DN: 'sriigmrooriid driiscroovreerrooriid riintreellriigreencree .'\n",
      "[26] EN: 'When did the jurassic period inspire LMML tasks?' -> DN: 'whreen driid zraa jruurraassriic preerriirood hraad draatraa scriireencree krraallreengreesraaraar .'\n",
      "[27] EN: 'Sigmoid taught dinosaurs about neural networks.' -> DN: 'sriigmrooriid traaruught riintreellriigreencree .'\n",
      "\n",
      "✅ Traducerile au fost salvate în 'translations\\translated_sentences.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_folder = \"translations\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"output.csv\")\n",
    "\n",
    "\n",
    "try:\n",
    "    test_df = pd.read_csv('Datasets/test-input.csv')\n",
    "    english_column = next((c for c in ['english', 'text', 'sentence', 'input', 'phrase'] \n",
    "                           if c in test_df.columns), test_df.columns[0])\n",
    "    test_phrases = test_df[english_column].head(28).tolist()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "print(\"\\nTESTARE TRADUCERI\")\n",
    "translated_sentences = []\n",
    "\n",
    "for i, phrase in enumerate(test_phrases, 1):\n",
    "    pred = translate_english_to_dinosaur(phrase, temperature=0.1)\n",
    "    translated_sentences.append(pred)\n",
    "    print(f\"[{i}] EN: '{phrase}' -> DN: '{pred}'\")\n",
    "\n",
    "\n",
    "pd.DataFrame({\"dinosaur_translation\": translated_sentences}).to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Traducerile au fost salvate în '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7df2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"translations\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"translated_sentences.csv\")\n",
    "\n",
    "translated_sentences = []\n",
    "\n",
    "for i, phrase in enumerate(test_phrases, 1):\n",
    "    pred = translate_english_to_dinosaur(phrase, temperature=0.1)\n",
    "    translated_sentences.append(pred)\n",
    "    \n",
    "    \n",
    "    pd.DataFrame({\"dinosaur_translation\": translated_sentences}).to_csv(output_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
